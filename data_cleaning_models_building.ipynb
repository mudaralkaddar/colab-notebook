{"cells":[{"cell_type":"code","source":["!pip install streamlit\n","!pip install pickle5"],"metadata":{"id":"rCu8n0yo-Nks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import required libraries.\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import sklearn\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","from scipy import stats as st\n","from imblearn import over_sampling\n","from sklearn.preprocessing import StandardScaler    \n","from sklearn.metrics import recall_score,precision_score,accuracy_score,f1_score,roc_curve,roc_auc_score\n","from sklearn.naive_bayes import GaussianNB \n","import re\n","import pickle\n","import streamlit as slt\n"],"metadata":{"id":"Lz697tLzzxjM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define function to calculate precision,accuracy,recall and F1_Score metrics as indicators of models' performance.\n","def conf_metrics_plot_cal(Y_test,Y_pred,cnf_matrix):\n","    \n","    #accuracy = (true positive + true negative)/(true positive+false positive + false negative + true negative).\n","    accuracy = accuracy_score(Y_test,Y_pred)#\n","   \n","    #recall = true positive / (true positive + false negative).\n","    recall = recall_score(Y_test,Y_pred)\n","    \n","    #precision = true positive / (true positive+false positive).\n","    precision = precision_score(Y_test,Y_pred)\n","    \n","    #F1_score =  2* Precision Score * Recall Score/ (Precision Score + Recall Score).\n","    f1 = f1_score(Y_test,Y_pred)\n","\n","    print(f'''accuracy is :{accuracy} \\n\n","          \\n precision is :{precision}\n","          \\n recall is :{recall}\n","          \\nF1_Score is : {f1}''')\n","    class_names=[-1,1] # name  of classes \n","\n","    fig, ax = plt.subplots() # figure to plot confusion matrix.\n","\n","    tick_marks = [-1,1]\n","\n","    # create heatmap and plot confusion matrix.\n","\n","    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g',xticklabels=['-1','1'],yticklabels=['-1','1']) \n","    \n","\n","    plt.tight_layout() \n","\n","    plt.title('Confusion matrix', y=1.1) \n","\n","    plt.ylabel('Actual label') \n","\n","    plt.xlabel('Predicted label')\n","\n"," "],"metadata":{"id":"fIv5LyC7xvMh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#read the dataset as pandas dataframe using the library pandas.\n","data=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/loan_data_set.csv\")\n"],"metadata":{"id":"KvaUrAId1VOb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#repalce categorical values with their corresponding numeric values 1 and -1.\n","data.replace([\"Male\",\"Yes\",\"Graduate\",\"Y\"],1,inplace=True)\n","data.replace([\"Female\",\"No\",\"Not Graduate\",\"N\"],-1,inplace=True)"],"metadata":{"id":"MO8cJgPo1mIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#replace Null values in LoanAmount column with the mean value of this column.\n","data[\"LoanAmount\"].fillna(np.mean(data[\"LoanAmount\"]),inplace=True)\n"],"metadata":{"id":"WgeI1LOG2c2v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#remove Loan_ID column from the dataframe.\n","data.drop(\"Loan_ID\",\"columns\",inplace=True)"],"metadata":{"id":"LM9jZ4SU2yC2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Replace each string number in Dependents column with its corresponding float number and convert integers numbers to float numbers .\n","for (i,j) in data[\"Dependents\"].iteritems() :\n","  if type(j) == str:\n","    data[\"Dependents\"][i] = float(re.sub('[^0-9]',\"\",j))\n","  elif type(j) == int :\n","     data[\"Dependents\"][i]=float(j)"],"metadata":{"id":"vmLFEsne27y9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Replace every null value with the mode value of its corresponding column in the dataframe.\n","for column in  data.loc[:, data.columns != \"LoanAmount\"]:\n","   data[column].fillna((st.mode(data[column])[0]).item(),inplace=True)"],"metadata":{"id":"LwMjiFge5vsJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ِSeperate dataframe columns to input data (all columns except the last one) and output data (Loan_Status column).\n","X = data.loc[:, data.columns != \"Loan_Status\"]\n","Y = data[\"Loan_Status\"]\n"],"metadata":{"id":"I5SLu0W9-esg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plot a pie chart that depict the percentage distribution of accepted and refused loan applications.\n","ones = sum([1 for i in Y if i == 1])\n","zeros = sum([1 for i in Y if i == -1])\n","fig = plt.figure(figsize =(10, 7))\n","plt.pie([ones,zeros], labels = [\"accepted\",\"refused\"],autopct='%1.1f%%')\n","plt.show()"],"metadata":{"id":"xUq4W2ZzBCj4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plot a pie chart that depict the percentage distribution of accepted and refused loan application after  classes (accept,refuse) balancing.\n","a= over_sampling.SMOTE()\n","X, Y = a.fit_resample(X, Y)\n","ones = sum([1 for i in Y if i == 1])\n","zeros = sum([1 for i in Y if i == -1])\n","fig = plt.figure(figsize =(10, 7))\n","plt.pie([ones,zeros], labels = [\"accepted\",\"refused\"],autopct='%1.1f%%')\n","plt.show()"],"metadata":{"id":"7B9TkcJjFPAH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ٍSeperate data into 80% for training (X_train,Y_train) and 20% for testing (X_test,Y_test).\n","X_train,X_test,Y_train,Y_test =  sklearn.model_selection.train_test_split(X, Y, test_size=0.2, random_state=40)\n","#Feature-scaling train and test input values.\n","st_x= StandardScaler()  \n","X_train= st_x.fit_transform(X_train)    \n","X_test= st_x.transform(X_test) "],"metadata":{"id":"_4e8yjakU10T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#logistic regression alogrithm programming.\n","logistic_regression = sklearn.linear_model.LogisticRegression(solver='liblinear') \n","logistic_regression.fit(X_train,Y_train)\n","\n","#save the model using pickle library.\n","filename1 = \"Completed_llogistic_regression_model.joblib\"\n","pickle.dump(logistic_regression, open(filename1, 'wb'))\n","\n","#Predict the outcomes of input values in the test group.\n","Y_pred1=logistic_regression.predict(X_test) \n","\n","#Comput and plot confusion matrix using the predicted outcome and the real outcome.\n","cnf_matrix_1 =metrics.confusion_matrix(Y_test, Y_pred1) \n","conf_metrics_plot_cal(Y_test,Y_pred1,cnf_matrix_1)\n","\n","#Plot the ROC(Receiver Operating Characteristics) curve and calculate the AUC(Area Under Curve) value.\n","fpr, tpr, _ = roc_curve(Y_test, Y_pred1)\n","auc = roc_auc_score(Y_test,Y_pred1)\n","fig2 = plt.figure(\"Figure 2\")\n","plt.plot(fpr, tpr, marker='.', label=f'AUC : {auc}')\n","plt.ylabel('TruePositiveRate')\n","plt.xlabel('FalsePositiveRate')\n","plt.legend()\n"],"metadata":{"id":"d4yuPmYJsOoe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Decision tree alogrithm programming.\n","tree = sklearn.tree.DecisionTreeClassifier() \n","tree.fit(X_train,Y_train)\n","\n","#save the model using pickle library.\n","filename2 = \"Completed_tree_model.joblib\"\n","pickle.dump(logistic_regression, open(filename2, 'wb'))\n","\n","#Predict the outcomes of input values in the test group.\n","y_pred2=tree.predict(X_test) \n","\n","#Comput and plot confusion matrix using the predicted outcome and the real outcome.\n","cnf_matrix_2 =metrics.confusion_matrix(Y_test, y_pred2) \n","conf_metrics_plot_cal(Y_test,y_pred2,cnf_matrix_2)\n","\n","#Plot the ROC(Receiver Operating Characteristics) curve and calculate the AUC(Area Under Curve) value.\n","fpr, tpr, _ = roc_curve(Y_test, y_pred2)\n","auc = roc_auc_score(Y_test,y_pred2)\n","fig2 = plt.figure(\"Figure 2\")\n","plt.plot(fpr, tpr, marker='.', label=f'AUC : {auc}')\n","plt.ylabel('TruePositiveRate')\n","plt.xlabel('FalsePositiveRate')\n","plt.legend()"],"metadata":{"id":"vN3_7mL-Olin"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Bayes regression alogrithm programming.\n","GNB = GaussianNB() \n","GNB.fit(X_train, Y_train) \n","\n","#save the model using pickle library.\n","filename3 = \"Completed_Bayesian_model.joblib\"\n","pickle.dump(logistic_regression, open(filename3, 'wb'))\n","\n","#Predict the outcomes of input values in the test group.\n","y_pred3 = GNB.predict(X_test) \n","\n","#Comput and plot confusion matrix using the predicted outcome and the real outcome.\n","cnf_matrix_3 =metrics.confusion_matrix(Y_test, y_pred3) \n","conf_metrics_plot_cal(Y_test,y_pred3,cnf_matrix_3)\n","\n","#Plot the ROC(Receiver Operating Characteristics) curve and calculate the AUC(Area Under Curve) value.\n","fpr, tpr, _ = roc_curve(Y_test, y_pred3)\n","auc = roc_auc_score(Y_test,y_pred3)\n","fig2 = plt.figure(\"Figure 2\")\n","plt.plot(fpr, tpr, marker='.', label=f'AUC : {auc}')\n","plt.ylabel('TruePositiveRate')\n","plt.xlabel('FalsePositiveRate')\n","plt.legend()"],"metadata":{"id":"HOaZ5GVvOmHf"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1un-0HVCjADwLX93JarQBsvedQEn2ZbVm","authorship_tag":"ABX9TyOtypFeZwet/Paua+A9+wkh"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}